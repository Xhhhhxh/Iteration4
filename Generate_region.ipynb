{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa06b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"preparation\").getOrCreate()\n",
    "\n",
    "import csv\n",
    "import pycountry\n",
    "import pycountry_convert as pc\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a8cafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(country_name):\n",
    "    try:\n",
    "        country_code = pycountry.countries.lookup(country_name).alpha_2\n",
    "        continent_code = pc.country_alpha2_to_continent_code(country_code)\n",
    "        continent_name = continent_code_to_name(continent_code)\n",
    "        return continent_name\n",
    "    except LookupError:\n",
    "\n",
    "        manual_mapping = {\n",
    "            'The Bahamas': 'Americas', 'The Gambia': 'Africa', 'Brunei': 'Asia', 'Cape Verde': 'Africa',\n",
    "            'Ivory Coast': 'Africa', 'Democratic Republic of the Congo': 'Africa', 'Guinea0Bissau': 'Africa',\n",
    "            'Vatican City': 'Europe', 'Republic of Ireland': 'Europe', 'Russia': 'Europe',\n",
    "            'Palestinian National Authority': 'Asia', 'East Timor': 'Asia', 'Turkey': 'Asia'}\n",
    "        return manual_mapping.get(country_name, None)\n",
    "\n",
    "def continent_code_to_name(continent_code):\n",
    "    continent_mapping = {\n",
    "        'AF': 'Africa', 'AS': 'Asia', 'EU': 'Europe', 'NA': 'Americas', 'OC': 'Oceania', 'SA': 'Americas'}\n",
    "    return continent_mapping.get(continent_code, None)\n",
    "\n",
    "input_file = \"global_education_data.csv\"\n",
    "output_file = \"region.csv\"\n",
    "\n",
    "# Read the CSV file and add the continent information\n",
    "with open(input_file, mode='r', encoding='utf-8') as infile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = ['Countries and areas', 'Region']\n",
    "    rows = []\n",
    "\n",
    "    for row in reader:\n",
    "        country_name = row['Countries and areas']\n",
    "        region = get_continent(country_name)\n",
    "        rows.append({'Countries and areas': country_name, 'Region': region})\n",
    "\n",
    "# Write the new CSV file \n",
    "with open(output_file, mode='w', encoding='utf-8', newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01a082df",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = spark.read.csv('region.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "198b34e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+\n",
      "|Countries and areas|  Region|\n",
      "+-------------------+--------+\n",
      "|        Afghanistan|    Asia|\n",
      "|            Albania|  Europe|\n",
      "|            Algeria|  Africa|\n",
      "|            Andorra|  Europe|\n",
      "|             Angola|  Africa|\n",
      "|           Anguilla|Americas|\n",
      "|Antigua and Barbuda|Americas|\n",
      "|          Argentina|Americas|\n",
      "|            Armenia|    Asia|\n",
      "|          Australia| Oceania|\n",
      "|            Austria|  Europe|\n",
      "|         Azerbaijan|    Asia|\n",
      "|        The Bahamas|Americas|\n",
      "|            Bahrain|    Asia|\n",
      "|         Bangladesh|    Asia|\n",
      "|           Barbados|Americas|\n",
      "|            Belarus|  Europe|\n",
      "|            Belgium|  Europe|\n",
      "|             Belize|Americas|\n",
      "|              Benin|  Africa|\n",
      "+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "region.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272df7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
